{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import toolbox\n",
    "import fcn\n",
    "import yaml\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import chainer\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "%load_ext autoreload\n",
    "# Note: this reload all lib at each cell exec, just for convenience\n",
    "%autoreload 2 \n",
    "\n",
    "chainer.print_runtime_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from models import InstanceSeg, SemanticSeg, PanopticSeg\n",
    "\n",
    "print(\"Preparing instance segmentation model...\", end=\" \")\n",
    "instaseg = InstanceSeg(\n",
    "    \"./2018-12-03_23-24/20181203_232507/params.yaml\",\n",
    "    \"./2018-12-03_23-24/20181203_232507/snapshot_model_45000.npz\",\n",
    "    gpu=0,\n",
    ")\n",
    "print(\"Done\")\n",
    "\n",
    "print(\"Preparing semantic segmentation model...\", end=\" \")\n",
    "semaseg = SemanticSeg(\n",
    "    \"./toolbox/deeplab/config/cocostuff164k.yaml\",\n",
    "    \"./cocostuff164k_iter100k.pth\",\n",
    "    gpu=0,\n",
    ")\n",
    "print(\"Done\")\n",
    "\n",
    "print(\"Preparing panotpic model...\", end=\" \")\n",
    "panoseg = PanopticSeg(instaseg, semaseg, thresh=0.7, frac=0.2)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a minival dataset, to quickly confirm things work\n",
    "dest_name = \"minival\"\n",
    "MINIVAL_SIZE = 100\n",
    "\n",
    "root = Path(\"./dataset/annotations/panoptic_val2017/\")\n",
    "r_labels = np.random.choice(list(root.glob(\"*.png\")), size=MINIVAL_SIZE, replace=False)\n",
    "r_images = [f.parent.parent.parent.joinpath(\n",
    "    \"val2017\").joinpath(\"{}.jpg\".format(f.stem)) for f in r_labels]\n",
    "\n",
    "r_labels[0].parent.parent.joinpath(dest_name).mkdir(exist_ok=True, parents=True)\n",
    "r_images[0].parent.parent.joinpath(dest_name).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "cp_r_labels = [f.parent.parent.joinpath(dest_name).joinpath(f.name) for f in r_labels]\n",
    "cp_r_images = [f.parent.parent.joinpath(dest_name).joinpath(f.name) for f in r_images]\n",
    "\n",
    "r_labels[0], cp_r_labels[0], r_images[0], cp_r_images[0]\n",
    "\n",
    "import shutil\n",
    "for src, dst in zip(r_labels, cp_r_labels):\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "for src, dst in zip(r_images, cp_r_images):\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "def predict_and_save(img, img_id, img_dir, tmp_json):    \n",
    "    segment, RGB = panoseg.predict(img, img_id)\n",
    "    \n",
    "    skimage.io.imsave(img_dir.joinpath(segment[\"file_name\"]), RGB)\n",
    "    with open(tmp_json.joinpath(\"{}.json\".format(img_id)), \"w\") as f:\n",
    "        json.dump(segment, f)\n",
    "\n",
    "# Make predictions for all test set.\n",
    "# Takes a while (~30h), so to make it more practical\n",
    "# it can be interrupted and continued.\n",
    "\n",
    "out_path = Path(\"./panopticapi/sample_data/\")\n",
    "split_name = \"panoptic_test2017_drcnn\"\n",
    "\n",
    "# Prepare directories for intermediate results\n",
    "img_dir = out_path.joinpath(split_name)\n",
    "img_dir.mkdir(parents=True, exist_ok=True)\n",
    "tmp_json = out_path.joinpath(\"{}_separated_json\".format(split_name))\n",
    "tmp_json.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Input images\n",
    "in_path = Path(\"./dataset/test2017/\")\n",
    "imgs = list(in_path.glob(\"*.jpg\"))\n",
    "\n",
    "errs = []\n",
    "\n",
    "_json_cache = out_path.joinpath(\"{}_separated_json\".format(split_name))\n",
    "for ip in tqdm(imgs):\n",
    "    id_img = int(ip.stem.lstrip(\"0\"))\n",
    "    \n",
    "    if _json_cache.joinpath(\"{}.json\".format(id_img)).exists():\n",
    "        continue\n",
    "    try:\n",
    "        img = skimage.io.imread(str(ip))\n",
    "        if img.ndim == 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            predict_and_save(img, id_img, img_dir, tmp_json)\n",
    "    except Exception as e:\n",
    "        errs.append({\"image\": str(ip), \"error\": str(e)})\n",
    "\n",
    "if len(errs) > 0:\n",
    "    with open(out_path.joinpath(\"{}_error_log.json\".format(split_name)), \"w\") as f:\n",
    "        json.dump(errs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all predictions\n",
    "\n",
    "buff = []\n",
    "for j in tmp_json.glob(\"*.json\"):\n",
    "    with j.open() as f:\n",
    "        buff.append(json.load(f))\n",
    "\n",
    "with open(out_path.joinpath(\"{}.json\".format(split_name)), \"w\") as f:\n",
    "    json.dump({\"annotations\": buff}, f)\n",
    "\n",
    "# shutil.rmtree(tmp_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
